import os
import random
import httpx
import json

class AgentEngine:
    """
    ðŸ§  ChainWarner Intelligent Agent (Dual-Mode)
    
    Mode A: DeepSeek/OpenAI (True AI)
    - Activated if 'LLM_API_KEY' env var is set.
    - Uses RAG to answer queries with full context.
    
    Mode B: Advanced Template Engine (Heuristic AI)
    - Fallback if no API key.
    - Uses deterministic logic to assemble sophisticated responses.
    - Simulates AI reasoning without cost.
    """
    
    def __init__(self):
        # Configuration
        # Secure: Read from environment variable
        self.api_key = os.getenv("LLM_API_KEY")
        self.api_base = os.getenv("LLM_API_BASE", "https://api.deepseek.com") # Default to DeepSeek
        self.model = os.getenv("LLM_MODEL", "deepseek-chat")
        
        # Professional Templates for Heuristic Mode (Chinese)
        self.templates = {
            "RISK_ANALYSIS": [
                "æ ¹æ®å¤šç»´æ·±åº¦åˆ†æžï¼Œ**{repo_name}** çš„é£Žé™©è¯„åˆ†ä¸º **{risk_percent}/100** ({status})ã€‚è¿™ä¸»è¦æ˜¯ç”±å…¶{driver_factor}å†³å®šçš„ã€‚",
                "ç³»ç»Ÿè®¡ç®—å‡º **{repo_name}** çš„é£Žé™©æŒ‡æ•°ä¸º **{risk_percent}**ã€‚{status} çŠ¶æ€è¡¨æ˜Ž{implication}ã€‚",
                "æ·±åº¦ä¾èµ–æ‰«ææ˜¾ç¤ºé£Žé™©æ°´å¹³ä¸º **{risk_percent}%**ã€‚ä¸»è¦è´¡çŒ®å› ç´ åŒ…æ‹¬{driver_factor}å’Œæ‹“æ‰‘ç»“æž„è„†å¼±æ€§ã€‚"
            ],
            "ECOSYSTEM_INSIGHT": [
                "OpenRank åˆ†æžæ˜¾ç¤ºè¯¥é¡¹ç›®çš„å½±å“åŠ›å¾—åˆ†ä¸º **{openrank_val}**ã€‚å®ƒæ˜¯å¼€æºç”Ÿæ€ä¸­çš„{rank_desc}çŽ©å®¶ã€‚",
                "å‡­å€Ÿ **{openrank_val}** çš„ OpenRankï¼Œ**{repo_name}** å±•çŽ°äº†{rank_desc}ç¤¾åŒºå½±å“åŠ›ã€‚æ´»è·ƒåº¦æ°´å¹³{activity_desc}ã€‚",
            ],
            "SECURITY_ADVICE": [
                "ðŸ’¡ **è¡ŒåŠ¨å»ºè®®**: é‰´äºŽ {risk_level} é£Žé™©ï¼Œæˆ‘ä»¬å»ºè®®{action}ã€‚ç‰¹åˆ«å…³æ³¨{focus_area}ã€‚",
                "ðŸ›¡ï¸ **ç¼“è§£ç­–ç•¥**: {action}ã€‚å›¾ç»“æž„è¡¨æ˜Žåœ¨{focus_area}å­˜åœ¨é«˜ä¸­ä»‹ä¸­å¿ƒæ€§èŠ‚ç‚¹ã€‚",
            ]
        }

    async def process_query(self, query: str, context: dict):
        """
        Smart Dispatcher: Try LLM first, fallback to Template Engine.
        """
        if self.api_key:
            try:
                # IMPORTANT: Ensure call_llm is awaited properly
                result = await self.call_llm(query, context)
                return result
            except Exception as e:
                print(f"[Agent] LLM Call Failed: {e}. Falling back to Template Engine.")
        
        return self.heuristic_response(query, context)

    async def call_llm(self, query: str, context: dict):
        """
        True AI: Call DeepSeek/OpenAI API with RAG context.
        """
        # 1. Prepare Context Summary
        root_node = context['nodes'][0] if context['nodes'] else {}
        repo_name = root_node.get('name', 'Unknown')
        risk_score = root_node.get('risk_score', 0.5)
        description = root_node.get('description', '')
        
        system_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªåä¸º ChainWarner AI çš„ä¸“å®¶ï¼Œä¸“æ³¨äºŽè½¯ä»¶ä¾›åº”é“¾å®‰å…¨å’Œå¼€æºç”Ÿæ€åˆ†æžã€‚
        
        å½“å‰é¡¹ç›®ä¸Šä¸‹æ–‡:
        - é¡¹ç›®åç§°: {repo_name}
        - é£Žé™©è¯„åˆ†: {risk_score:.2f} (0=å®‰å…¨, 1=å±é™©)
        - å…³é”®æŒ‡æ ‡: {description}
        - ä¾èµ–æ•°é‡: {len(context['nodes']) - 1}
        
        æŒ‡ä»¤:
        - è¯·æ ¹æ®ä¸Šè¿°ä¸Šä¸‹æ–‡å›žç­”ç”¨æˆ·çš„æé—®ã€‚
        - å›žç­”å¿…é¡»ä½¿ç”¨**ä¸­æ–‡**ã€‚
        - ä¿æŒä¸“ä¸šã€ç®€æ´ä¸”æœ‰æ´žå¯ŸåŠ›ã€‚
        - å…³é”®æŒ‡æ ‡æ•°å€¼è¯·ä½¿ç”¨åŠ ç²—æ˜¾ç¤ºã€‚
        """
        
        async with httpx.AsyncClient() as client:
            resp = await client.post(
                f"{self.api_base}/chat/completions",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": query}
                    ],
                    "temperature": 0.3
                },
                timeout=10.0
            )
            data = resp.json()
            return data['choices'][0]['message']['content']

    def heuristic_response(self, query: str, context: dict):
        """
        Fallback: sophisticated rule-based generation.
        """
        query = query.lower()
        
        # Extract Variables
        root = context['nodes'][0] if context['nodes'] else {}
        repo_name = root.get('name', 'æœªçŸ¥é¡¹ç›®')
        risk = root.get('risk_score', 0.5)
        percent = round(risk * 100, 1)
        
        # Parse Description for hidden metrics (OpenRank/Constraint)
        desc = root.get('description', '') # "Constraint: 0.12 | Rank: 0.85"
        openrank_val = "æœªçŸ¥"
        constraint_val = "æœªçŸ¥"
        
        if "Rank:" in desc:
            try:
                # Rank: 0.85 -> Normalized score. Let's convert back to rough raw OpenRank for display
                rank_score = float(desc.split("Rank:")[1].strip())
                openrank_val = f"{rank_score * 1000:.0f}" # Reverse normalization approx
            except:
                pass
                
        # Determine Status (Chinese)
        if risk < 0.4:
            status = "å®‰å…¨ âœ…"
            risk_level = "ä½Ž"
            implication = "å¼€å‘å®žè·µç¨³å®š"
            driver_factor = "é«˜ OpenRank å’ŒæŒç»­çš„æ´»è·ƒåº¦"
            rank_desc = "ä¸»å¯¼åž‹"
            activity_desc = "å¼ºåŠ²"
            action = "ä¿æŒå½“å‰çš„å®¡è®¡è®¡åˆ’"
            focus_area = "ä¼ é€’æ€§ä¾èµ–"
        elif risk < 0.7:
            status = "è­¦å‘Š âš ï¸"
            risk_level = "ä¸­ç­‰"
            implication = "æ½œåœ¨çš„ç»“æž„æ€§å¼±ç‚¹"
            driver_factor = "å¤æ‚çš„ä¾èµ–é“¾"
            rank_desc = "æˆé•¿åž‹"
            activity_desc = "æ³¢åŠ¨"
            action = "é”å®šä¾èµ–ç‰ˆæœ¬"
            focus_area = "ç›´æŽ¥ä¾èµ–"
        else:
            status = "é«˜å± ðŸš¨"
            risk_level = "é«˜"
            implication = "æ€¥éœ€å®‰å…¨å…³æ³¨"
            driver_factor = "é«˜ç»“æž„æ´žçº¦æŸå’Œä½Žæ´»è·ƒåº¦"
            rank_desc = "å°ä¼—/è¾¹ç¼˜"
            activity_desc = "åœæ»ž"
            action = "ç«‹å³è¿›è¡Œäººå·¥ä»£ç å®¡æŸ¥"
            focus_area = "å®‰å…¨è¡¥ä¸"

        # Intent Routing
        # Use simple keyword matching for Chinese/English
        if any(w in query for w in ["risk", "score", "safe", "status", "é£Žé™©", "å®‰å…¨", "åˆ†æ•°"]):
            tpl = random.choice(self.templates["RISK_ANALYSIS"])
            return tpl.format(
                repo_name=repo_name, risk_percent=percent, status=status,
                driver_factor=driver_factor, implication=implication
            )
            
        elif any(w in query for w in ["rank", "influence", "community", "trend", "æŽ’å", "å½±å“", "ç¤¾åŒº", "è¶‹åŠ¿"]):
            tpl = random.choice(self.templates["ECOSYSTEM_INSIGHT"])
            return tpl.format(
                repo_name=repo_name, openrank_val=openrank_val,
                rank_desc=rank_desc, activity_desc=activity_desc
            )
            
        elif any(w in query for w in ["fix", "advice", "suggestion", "help", "å»ºè®®", "ä¿®å¤", "æ€Žä¹ˆåŠž"]):
            tpl = random.choice(self.templates["SECURITY_ADVICE"])
            return tpl.format(
                risk_level=risk_level, action=action, focus_area=focus_area
            )
            
        # Default General Response
        return f"æˆ‘å·²ç»åˆ†æžäº† **{repo_name}**ã€‚å®ƒçš„é£Žé™©è¯„åˆ†ä¸º **{percent}**ï¼ŒOpenRank ä¸º **{openrank_val}**ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥è¿›ä¸€æ­¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
